So much of practical applications of deep learning today, machine learning and AI in general, use a paradigm called supervised learning, which I'm sure most of you have heard of before. So this is the paradigm by which you train a machine by showing examples of inputs and outputs. You want to build a machine to distinguish images of cars from airplanes, you show it an image of a car, if the machine says car, you don't do anything, if it says something else, you adjust the internal parameters of the system so that the output gets closer to the one you want. So imagine the target output is some vector of activities on a set of outputs, you want this vector coming out of the machine to get closer to the vector that is the desired output. This works really well, as long as you have lots of data, it works for speech recognition, image recognition, face recognition, generating captions, translation, all kinds of stuff, right. So, this is I would say, 95% of all applications of machine learning today.  

There are two other paradigms, one of which I will not talk about, one of which I will talk about a lot. So the two other paradigms are reinforcement learning, which I will not talk about. And there are other courses, there is a course by Larry Pinto about this, that I encourage you to take. And third paradigm is self supervised learning or unsupervised learning. And we'll talk about this quite a lot in the following weeks. But for now, let's talk about supervised learning.  Supervised learning, you could think of it as kind of a play on supervised learning. So the traditional model of pattern recognition, machine learning and supervised learning, certainly going back to the late 50s, early 60s, is the idea by which you take a raw signal, let's say an image or an audio signal, or a set of features representing an object. And then you turn it into a representation using a feature extractor, which in the past was hand engineered. And then you take that representation, which is generally in the form of a vector or a table of numbers, or some kind of tensor, multi dimensional array. But sometimes, you know, it could be a different type of representation. And you feed that to a trainable classifier. So this is where the learning takes part, this is the classical model, and is still popular, it's still used a lot. 

But basically, what deep learning has done is replace this sort of main manual hand engineering of the feature extractor by a stack of trainable modules if you want. So the main idea of deep learning, and the only reason why it's called Deep is that we stack a bunch of modules, each of which transforms the input a little bit into something that's going to a slightly higher level of abstraction if you want, and, and then we train the entire system end to end. So I represented those sort of pinkish modules to indicate the ones that are trainable. And the blue modules are the fixed ones, the engineered ones. So that's, that's why deep learning is called Deep, we stack multiple layers of trainable things, and we train it end to end. The idea for this goes back a long time, the practical methods for this go back to the mid to late 80s. With the backpropagation algorithm, which can be is going to be the main subject of today's lecture actually. And, but it took a long time for this idea to actually percolate and sort of become the, the main tool that people use to build machine learning system. It's only about 10 years old. 

Okay, so let's go through a few definitions. So we're going to deal with parameterize models a parameterized model or running model, if you want is a parametrized function, g of x and W where x is the input and w is a set of parameters. I'm representing this here on the right with a particular symbolism where a function like this, that produces a single output, think of the output as either a vector or matrix or a tensor, or perhaps even a scalar. But, but generally is multi dimensional, it can actually be something else in a multi dimensional array, but something that, you know, maybe like a sparse array representation or graph with values on it. But for now, let's think of it just as a multi dimensional array. So both the inputs and the outputs are multi dimensional arrays, what people called tensors, it's not really kind of the appropriate definition of tensor, but that's okay.
And that function is parameterized, by a set of parameters W, those are the knobs that we're going to adjust during training. And they basically determine the input output relationship between, you know, between the input x and the predicted output y bar. Okay, so I'm not implicitly not explicitly representing the wire that comes in with W. Here, I kind of assumed that w is somewhere inside of this of this module, think of this as an object in object oriented programming. So it's an instance of a class that you instantiated and it's got a slot in it that represents the parameters and there is a forward function basically, that takes as argument the input and returns the output, okay. 

So, a basic running machine will have a cost function, and the cost function in supervised learning, but in also in some other settings, will basically compute the discrepancy, distance, divergence, whatever you want to call it between the desired output y, which is given to you from the training set, and the output produced by the system y bar. Okay, so an example of this, a very simple example of setting like this is linear regression, a linear regression, x is a vector composed of components, x is W is also a vector, and the output is a scalar. That is simply the dot product of x with W. So y bar now is a scalar. And what you compute is the square distance, the square difference really, between y and y bar, if W is a matrix, then now y is a vector, and you compute the square norm of the difference between y and y bar. And that's basically linear regression. So learning will consist in finding the set of W's that minimize this particular cost function average over a training set, I'll come to this in a minute. But I want you to think right now about the fact that this g function may not be something particularly simple to compute. So it may not be just multiplying a vector by a matrix, it may not be just, you know, carrying some sort of fixed computation with sort of a fixed number of steps, it could involve something complicated, it could involve, you know, minimizing a function with respect to some other variable that you don't know. It could involve, you know, a lot of iteration of some algorithm that converges towards a fixed point. So it's not kind of restrict ourselves to g of x or w that are kind of simple things. It could be very complicated things. And we'll come to this in a few weeks. Right.

So, this is just to kind of explain the notations that I will use during the course of this, this class.  So we have observed input and desired output variables, those are kind of gray, grayish bubbles. other variables that are produced by the system, or internal to the system, are those kind of, you know, empty circle variables. We have deterministic functions or functions that are, so they are indicated by this sort of rounded shape. Here, they can take multiple inputs and multiple outputs. And each of those can be tensors, or scalars, or whatever. And they have implicit parameters that are tunable by training. And then we have a cost function. So cost functions are basically functions that take one or multiple inputs, and I put a scalar, but I'm not representing the output, it's implicit. Okay. So if you have a Red Square, it has an implicit output. And it says it's a scalar. And we interpret it as a cost or an energy function. So this symbolism is kind of similar to what people use in graphical models, if you if you heard what a graphical model is, particularly the type of graphical model called a factor graph. So the factor graph you have those variable bubbles and you have those factors, which are those square cost functions, you don't have this idea that you have deterministic functions in it, because graphical models don't care about the fact that you have functions in one direction or another. But here we care about it.