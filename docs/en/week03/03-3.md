---
lang-ref: ch.03-3             
title: Spiral classification 
lecturer: Alfredo Canziani 
authors: Wenhao Li          
date: 6 May 2021        
---                    




## Diagram.net

Diagrams.net is a great tool to draw neural network diagrams. Next we will introduce a few rules to make our diagrams more consistent with the ones in lecture.



<center>
<img src="{{site.baseurl}}/images/week03/03-3/figure7.png" style="background-color:#DCDCDC;" /><br>
</center>

The grayscale background means this is an observation, which means they are data points from a given dataset. You can check the input and labels by going to the directory of the dataset if you want.

<center>
<img src="{{site.baseurl}}/images/week03/03-3/figure9.png" style="background-color:#DCDCDC;" /><br>
</center>

We use "Delay" to denote the encoder(e.g., neural network).


<center>
<img src="{{site.baseurl}}/images/week03/03-3/figure10.png" style="background-color:#DCDCDC;" /><br>
</center>

In this example, $\vect{x}$ and $\vect{y}$  are observations.

In the half above, we feed the $\vect{x}$ to a given encoder to get a prediction $\bar {\vect{y}}$. This is called forward propagation.

In the half below, we want to get the prediction $\bar{\vect{x}}$ given observation $\vect{y}$. We keep doing gradient descent to make the network output as close as to $\vect{y}$. This is called amortizing inference. This example shows that backpropagation is NOT only used for training. Backpropagation can be used for inference.



## [Spiral Classification](https://atcold.github.io/pytorch-Deep-Learning/en/week02/02-3/)
